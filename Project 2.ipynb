{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset Representation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Processing of Dataset into Dataframe\n",
    "Load the dataset into a DataFrame. Perform necessary operations to properly load your dataset into a DataFrame."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "source": [
    "col_names = [\"atmpt1\", \"atmpt2\", \"atmpt3\", \"atmpt4\", \"atmpt5\", \"atmpt6\", \"atmpt7\", \"atmpt8\"]\r\n",
    "df = pd.read_csv('Dataset1.csv', names=col_names)\r\n",
    "\r\n",
    "df = (df.fillna(0)).astype({'atmpt1' : int, 'atmpt2' : int, 'atmpt3' : int, 'atmpt4' : int, 'atmpt5' : int, 'atmpt6' : int, 'atmpt7' : int, 'atmpt8' : int})\r\n",
    "cols = [\"atmpt1\", \"atmpt2\", \"atmpt3\", \"atmpt4\", \"atmpt5\", \"atmpt6\", \"atmpt7\", \"atmpt8\"]\r\n",
    "df[cols] = df[cols].replace(0, np.nan)\r\n",
    "df[\"atmpt1\"] = df[\"atmpt1\"].replace(np.nan, 0)\r\n",
    "indices, rowSeries = zip(*df.iterrows())\r\n",
    "\r\n",
    "list = []\r\n",
    "for x in rowSeries:\r\n",
    "    remove_nan = x.dropna()\r\n",
    "    remove_nan = remove_nan.astype(int)\r\n",
    "    list.append(remove_nan.to_numpy())\r\n",
    "\r\n",
    "list\r\n",
    "    \r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0   1   2   3   4   5   6   7   8   9   10  11  12  13  14  15  16  17  \\\n",
       "0     0   0   0   0   0   1   0   0   0   0   0   0   0   0   1   0   0   0   \n",
       "1     1   0   1   0   0   0   0   0   0   0   1   0   1   0   0   0   0   0   \n",
       "2     0   0   0   1   0   1   0   0   0   0   0   0   0   1   1   0   1   1   \n",
       "3     0   1   0   1   1   0   0   1   0   1   1   0   0   0   1   0   0   1   \n",
       "4     0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   1   1   \n",
       "..   ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..   \n",
       "295   0   0   0   0   0   0   0   0   1   0   0   0   0   1   1   0   0   0   \n",
       "296   0   0   0   0   1   0   1   0   0   1   0   1   0   0   0   0   0   0   \n",
       "297   0   0   1   0   1   0   0   0   1   0   0   1   1   0   0   0   0   0   \n",
       "298   0   0   0   0   0   1   1   1   0   1   0   0   0   1   1   0   1   0   \n",
       "299   0   0   0   0   0   1   1   0   0   0   0   0   0   0   0   0   0   0   \n",
       "\n",
       "     18  19  \n",
       "0     0   0  \n",
       "1     0   0  \n",
       "2     0   1  \n",
       "3     0   0  \n",
       "4     0   0  \n",
       "..   ..  ..  \n",
       "295   0   0  \n",
       "296   0   0  \n",
       "297   0   0  \n",
       "298   0   0  \n",
       "299   0   0  \n",
       "\n",
       "[300 rows x 20 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 102
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Brief Description of the Dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The dataset we chose is named \"Dataset1\" which contains 300 observations containing a series of numbers sorted in ascending order. The amount of numbers per row varies between observations and is not consistent within the dataset. Looking at the initial structure of the dataset afetr turning into a Datframe, we can safely assume that it is an Associate Rule Mining dataset."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Structure of the Dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "df.columns"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['atmpt1', 'atmpt2', 'atmpt3', 'atmpt4', 'atmpt5', 'atmpt6', 'atmpt7',\n",
       "       'atmpt8'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "df.info()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 300 entries, 0 to 299\n",
      "Data columns (total 8 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   atmpt1  300 non-null    int32\n",
      " 1   atmpt2  300 non-null    int32\n",
      " 2   atmpt3  300 non-null    int32\n",
      " 3   atmpt4  300 non-null    int32\n",
      " 4   atmpt5  300 non-null    int32\n",
      " 5   atmpt6  300 non-null    int32\n",
      " 6   atmpt7  300 non-null    int32\n",
      " 7   atmpt8  300 non-null    int32\n",
      "dtypes: int32(8)\n",
      "memory usage: 9.5 KB\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Discuss the observations in the dataset file. \n",
    "What does each observation represent? Since the dataset description is not provided, the group can presume the entity represented by each observation. For example:\n",
    "- For an association rule mining dataset, the group may presume that an observation represents a customer transaction from a store, a list of words in a document, and other similar examples.\n",
    "- For a clustering dataset, the group may presume that an observation represents a song from a group of songs, an image from a group of images, and other similar examples.\n",
    "- For a collaborative filtering dataset, the group may presume that an observation represents a movie being rated by people, a book being rated by readers, and other similar examples."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The Dataset that will be used for this Project is named \"Dataset1\" which contains 300 observations each containing a series of numbers which, based on our internal discussion, we will represent as a student's set of scores for a retakeable online quiz. As the dataset is an **association rule mining** dataset, we chose to represent the Dataset as such because its data fits the description of our representation quite well and is very relevant to our current situation during the pandemic."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Discuss the variables in the dataset file. \n",
    "Since the description of the dataset is not provided, the group can presume the entity represented by each variable. For example:\n",
    "- For an association rule mining dataset, the group may presume that a variable represents the presence of a certain item in a customer transaction from a store, the presence of a word in a document, and other similar examples.\n",
    "- For a clustering dataset, the group may presume that a variable represents a certain characteristic or feature of a song (i.e., value representing the tempo, rhythm, pitch, and others), a certain characteristic or feature of an image (i.e., amount of black, amount of white, and others), and other similar examples.\n",
    "- For a collaborative filtering dataset, the group may presume that a variable represents a rating of a specific person to a movie,"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "There are 8 variables in the dataset our group has chosen and they represent attempts made by the student to answer the online quiz. This is why we chose to name every column (as seen below) after each of the students' attempt in taking the online quiz. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "df.columns"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['atmpt1', 'atmpt2', 'atmpt3', 'atmpt4', 'atmpt5', 'atmpt6', 'atmpt7',\n",
       "       'atmpt8'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exploratory Data Analysis\n",
    "Perform exploratory data analysis comprehensively to gain a good understanding of your\n",
    "dataset. The exploratory data analysis should guide you in formulating the research\n",
    "questions of the project.\n",
    "\n",
    "In this section of the notebook, you must fulfill the following:\n",
    "• Identify 2 interesting exploratory data analysis questions. Properly state the\n",
    "questions in the notebook.\n",
    "\n",
    "• Answer the EDA questions using both:\n",
    "    o Numerical Summaries – measures of central tendency, measures of\n",
    "    dispersion, and correlation\n",
    "    \n",
    "    o Visualization – Appropriate visualization should be used. Each visualization should be accompanied by a brief explanation.\n",
    "\n",
    "• To emphasize, both numerical summary and visualization should be present to answer each question. The whole process should be supported with verbose textual descriptions of your procedures and findings."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Mining\n",
    "\n",
    "Identify the correct data mining technique to apply to your chosen dataset. The technique that you will apply should be appropriate for the dataset. Apply the data mining technique with the provided hyperparameters and answer the provided questions.\n",
    "\n",
    "For Association Rule Mining:\n",
    "- Use the rule_miner.py file from our exercises. Make sure that your code is working properly. Set support_t to 10 and the confidence_t to 0.6.\n",
    "- Perform association rule mining.\n",
    "- Answer the question: Using the provided support threshold and confidence threshold, what is/are the association rules that we derived from the dataset?\n",
    "\n",
    "For Clustering:\n",
    "- State the number of observations per group before clustering.\n",
    "- Use the kmeans.py file from our exercises. Make sure that your code is working properly. Set the k, start_var, end_var, num_observations, and data to their appropriate values according to the dataset.\n",
    "- Perform clustering with maximum iterations set to 300.\n",
    "- Answer the question: After clustering, how many observations of each class are included in per cluster?\n",
    "\n",
    "For Collaborative Filtering:\n",
    "- Use the collaborative_filtering.py file from our exercises. Make sure that your code is working properly. Set k to 5.\n",
    "- Perform collaborative filtering.\n",
    "- Answer the question: Give the top 5 items that are most similar to the item at index 0."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import the `RuleMiner` class"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "from rule_miner import RuleMiner"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Set `support_t` equal to `10` and `confidence_t` equal to `0.6`. The field `support_t` represents the support threshold, while the field `confidence_t` represents the confidence threshold."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "rule_miner = RuleMiner(10, 0.6)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As of now, our dataset is represented as a list of list. Instead of using this representation, we will convert our dataset to a matrix represented as a `pandas` `DataFrame`. The `DataFrame` will contain 300 rows - equivalent to the number of observations in the dataset, and 8 columns - equivalent to the number of distinct items in the dataset. The value in the cell in row `x` and column `y` is 1 if item `y` is in observation (basket) `x`, otherwise, the value in the cell in row `x` and column `y` is 0."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "source": [
    "syn_df = pd.DataFrame([[0 for _ in range(20)] for _ in range(300)], columns=[i for i in range(20)])\r\n",
    "for i, listitem in enumerate(list):\r\n",
    "    syn_df.iloc[i, listitem] = 1\r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Open `rule_miner.py` file and complete the `get_support()` function. This function returns the support for an itemset. The support of an itemset refers to the number of baskets wherein the itemset is present."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Implement the `get_support()` function. Inline comments should help you in completing the contents of the function. Upon implementing the function, execute the code below then answer the questions."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "source": [
    "print(rule_miner.get_support(syn_df, [0]))\r\n",
    "print(rule_miner.get_support(syn_df, [0, 1]))\r\n",
    "print(rule_miner.get_support(syn_df, [0, 1, 2]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "68\n",
      "17\n",
      "4\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "frequent_itemsets = rule_miner.get_frequent_itemsets(df)\r\n",
    "print(frequent_itemsets)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The frequent itemsets in the dataset, given the support threshold 10, is the set: `[['atmpt1'], ['atmpt2']]`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Using the `get_rules()` function in `rule_miner.py`, let us list all the possible rules for all frequent itemsets in our dataset. The `get_rules()` function returns a list of rules produced from an itemset."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for itemset in frequent_itemsets:\r\n",
    "    print(rule_miner.get_rules(itemset))"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Insights and Conclusions\n",
    "Clearly state your answers from the data to answer each provided question. Make sure that all conclusions are backed up with proper data mining procedures."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.4 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}